

I am a machine learning researcher and a PhD candidate in artificial intelligence and machine learning. I hold a Masters of Science degree in Electrical Engineering and Information Technology from Karlsruhe Institute of Technology. I wrote my MSc thesis at University of California, Berkeley. My current research focus is robustness and generalization in machine learning.



### Publications

[1] Ezgi Korkmaz. Investigating Vulnerabilities of Deep Neural Policies. Conference on Uncertainty in Artificial Intelligence (UAI), 2021.<br />
**[Acceptance Rate: 26.38%]**[[Paper]](https://www.auai.org/uai2021/pdf/uai2021.635.pdf)

[2] Ezgi Korkmaz. Inaccuracy of State-Action Value Function For Non-Optimal Actions in Adversarially Trained Deep Neural Policies. IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPR) **[Oral Presentation]**, 2021 & International Conference on Learning Representation (ICLR) Robust and Reliable Machine Learning in the Real World Workshop, 2021.[[Paper]](https://ieeexplore.ieee.org/document/9523170) [[Slides]](https://www.youtube.com/watch?v=F3cvXrLWcoU&t=3s&ab_channel=AngelinaWang)

[3] Ezgi Korkmaz. Non-Robust Feature Mapping in Deep Reinforcement Learning. International Conference on Machine Learning (ICML) A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning Workshop, 2021.

[4]  Ezgi Korkmaz. Adversarial Training Blocks Generalization in Neural Policies. International Conference on Learning Representation (ICLR) Robust and Reliable Machine Learning in the Real World Workshop, 2021 & Conference on Neural Information Processing Systems (NeurIPS) Safe and Robust Control of Uncertain Systems Workshop, 2021 & Conference on Neural Information Processing Systems (NeurIPS) I Can't Believe It's Not Better Workshop, 2021. [[Paper]](naturalEK.pdf)

[5] Ezgi Korkmaz. A Brief Summary on COVID-19 Pandemic and Machine Learning Approaches. International Joint Conference on Artificial Intelligence (IJCAI) Workshop on Artificial Intelligence for Social Good, 2021. [[Paper]](ijcai21EK.pdf)

[6] Ezgi Korkmaz. Nesterov Momentum Adversarial Perturbations in the Deep Reinforcement Learning Domain. International Conference on Machine Learning (ICML) Inductive Biases, Invariances and Generalization in Reinforcement Learning Workshop, 2020.

[7] Ezgi Korkmaz. Adversarially Trained Neural Policies in Fourier Domain. International Conference on Learning Representation (ICLR) Robust and Reliable Machine Learning in the Real World Workshop,2021 & International Conference on Machine Learning (ICML) A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning Workshop, 2021.




